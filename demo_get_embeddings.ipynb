{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0224a832",
   "metadata": {},
   "source": [
    "Source https://www.kaggle.com/thomasmichel/use-models-from-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd253c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from shopee.image import get_embeddings\n",
    "from shopee.image.data import ImageInferenceDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using the following device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8039c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOPEE_DATA_PATH = '/opt/jsk/share/shopee-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3f20d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "COMPUTE_CV = False\n",
    "\n",
    "test = pd.read_csv(f'{SHOPEE_DATA_PATH}/test.csv')\n",
    "if len(test)>3: COMPUTE_CV = False\n",
    "else: print('this submission notebook will compute CV score, but commit notebook will not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70beb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/opt/jsk/share/shopee-models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c03cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"efficientnet_b0\"\n",
    "weights_paths = {\n",
    "    \"pretrained\": f\"{PATH}/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\",\n",
    "    \"arcface_triplets\": f\"{PATH}/image/efficientnet/efficientnet_b0_finetuned_arcface_triplets.pth\"\n",
    "}\n",
    "\n",
    "weights = \"arcface_triplets\"\n",
    "\n",
    "# load model architecture\n",
    "image_model = torch.hub.load(\n",
    "    f\"{PATH}/hub/rwightman_gen-efficientnet-pytorch_master/\",\n",
    "    model_name,\n",
    "    pretrained=False,\n",
    "    source=\"local\"\n",
    ")\n",
    "\n",
    "# load pre-trained weights\n",
    "image_model.load_state_dict(torch.load(\n",
    "    weights_paths[\"pretrained\"],\n",
    "    map_location=\"cpu\"\n",
    "))\n",
    "\n",
    "# remove last layer (classification layer)\n",
    "image_model = nn.Sequential(*list(image_model.children())[:-1])\n",
    "\n",
    "if weights == \"arcface_triplets\":\n",
    "    image_model.load_state_dict(torch.load(\n",
    "            weights_paths[weights],\n",
    "            map_location=\"cpu\"\n",
    "        ))\n",
    "\n",
    "image_model.eval()\n",
    "image_model.to(\"cpu\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9316a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    data = pd.read_csv(f'{SHOPEE_DATA_PATH}/train.csv')\n",
    "    images_path = f'{SHOPEE_DATA_PATH}/train_images/'\n",
    "    print('Using train as test to compute CV (since commit notebook). Shape is', data.shape )\n",
    "else:\n",
    "    data = pd.read_csv(f'{SHOPEE_DATA_PATH}/test.csv')\n",
    "    images_path = f'{SHOPEE_DATA_PATH}/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec136dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing image embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2110b18c67f4c7a8f46ccb490e56cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image embeddings shape torch.Size([3, 1280])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_workers = 2\n",
    "\n",
    "image_embeddings = get_embeddings(\n",
    "    data,\n",
    "    images_path,\n",
    "    image_model,\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
